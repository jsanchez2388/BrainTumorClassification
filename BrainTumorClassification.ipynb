{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import Tensor\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_directory = \"archive/Training\"\n",
    "test_directory = \"archive/Testing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((224, 224)),\n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "\n",
    "dataset = torchvision.datasets.ImageFolder(root=train_directory, transform=transform)\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "def calculate_mean_std(loader):\n",
    "    mean = 0.\n",
    "    std = 0.\n",
    "    total_images_count = 0\n",
    "\n",
    "    for images, _ in loader:\n",
    "        # Rearrange batch to be the shape of [B, C, W * H]\n",
    "        images = images.view(images.size(0), images.size(1), -1)\n",
    "        # Update total number of images\n",
    "        total_images_count += images.size(0)\n",
    "        # Compute mean and std here\n",
    "        mean += images.mean(2).sum(0) \n",
    "        std += images.std(2).sum(0)\n",
    "\n",
    "    # Final step\n",
    "    mean /= total_images_count\n",
    "    std /= total_images_count\n",
    "\n",
    "    return mean, std\n",
    "\n",
    "mean, std = calculate_mean_std(loader)\n",
    "print(f'Mean: {mean}')\n",
    "print(f'Std: {std}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# PyTorch transform image set up\n",
    "\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "    # Resize all images to 224 x 224 pixel image\n",
    "    torchvision.transforms.Resize((224,224)),\n",
    "    torchvision.transforms.RandomRotation(10),\n",
    "    \n",
    "    # Give the image a random crop\n",
    "    torchvision.transforms.RandomResizedCrop(size=(224,224), scale=(0.8,1.0), ratio=(1.0,1.0)),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomVerticalFlip(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=mean.tolist(),std=std.tolist())\n",
    "])\n",
    "\n",
    "\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((224,224)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=mean.tolist(),std=std.tolist())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import images\n",
    "train_dataset = DataLoader(torchvision.datasets.ImageFolder(root=train_directory, transform=transform_train),\n",
    "                           batch_size=16, shuffle=True)\n",
    "test_dataset = DataLoader(torchvision.datasets.ImageFolder(root=test_directory, transform=transform_test),\n",
    "                          batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Show Transformed Images\n",
    "\n",
    "def show_transformed_images(dataset):\n",
    "    loader = dataset\n",
    "    batch = next(iter(loader))\n",
    "    images, labels = batch\n",
    "\n",
    "    grid = torchvision.utils.make_grid(images, nrow=3)\n",
    "    plt.figure(figsize=(11,11))\n",
    "    plt.imshow(np.transpose(grid,(1,2,0)))\n",
    "    print('labels: ', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_transformed_images(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "----\n",
    "# Setting up DenseNet\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# DenseLayer / Convolutional Layer\n",
    "\n",
    "class DenseLayer(nn.Module):\n",
    "    def __init__(self,input_channels, growth_rate, bottle_neck_size, drop_rate, memory_efficient=False):\n",
    "        super(DenseLayer, self).__init__()\n",
    "        self.add_module('norm1',nn.BatchNorm2d(input_channels))\n",
    "        self.add_module('relu1',nn.ReLU(inplace=True))\n",
    "        self.add_module('conv1',nn.Conv2d(input_channels, bottle_neck_size * growth_rate,\n",
    "                                          kernel_size=1, stride=1, bias=False))\n",
    "        self.add_module('norm2', nn.BatchNorm2d(bottle_neck_size * growth_rate))\n",
    "        self.add_module('relu2', nn.ReLU(inplace=True))\n",
    "        self.add_module('conv2',nn.Conv2d(bottle_neck_size * growth_rate, growth_rate,\n",
    "                                          kernel_size=3, stride=1, padding=1, bias=False))\n",
    "        self.drop_rate = float(drop_rate)\n",
    "        self.memory_efficient = memory_efficient\n",
    "\n",
    "    def bn_function(self, inputs):\n",
    "        \"\"\"Bottleneck Function\"\"\"\n",
    "        '''type: (List[Tensor]) -> Tensor'''\n",
    "        concated_features = torch.cat(inputs, 1)\n",
    "        bottleneck_output = self.conv1(self.relu1(self.norm1(concated_features)))\n",
    "        return bottleneck_output\n",
    "\n",
    "    def forward(self, input):\n",
    "        if isinstance(input, Tensor):\n",
    "            prev_features = [input]\n",
    "        else:\n",
    "            prev_features = input\n",
    "\n",
    "        bottleneck_output = self.bn_function(prev_features)\n",
    "        new_features = self.conv2(self.relu2(self.norm2(bottleneck_output)))\n",
    "        if self.drop_rate > 0:\n",
    "            new_features = F.dropout(new_features, p=self.drop_rate, training=self.training)\n",
    "\n",
    "        return new_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# DenseBlock\n",
    "\n",
    "class DenseBlock(nn.ModuleDict):\n",
    "    _version = 2\n",
    "\n",
    "    def __init__(self, num_layers, input_channels,bottle_neck_size, growth_rate, drop_rate, memory_efficient=False):\n",
    "        super(DenseBlock, self).__init__()\n",
    "        for i in range(num_layers):\n",
    "            layers = DenseLayer(\n",
    "                input_channels + i * growth_rate,\n",
    "                growth_rate=growth_rate,\n",
    "                bottle_neck_size=bottle_neck_size,\n",
    "                drop_rate=drop_rate,\n",
    "                memory_efficient=memory_efficient)\n",
    "            self.add_module('denselayer%d' % (i + 1), layers)\n",
    "\n",
    "    def forward(self, init_features):\n",
    "        features = [init_features]\n",
    "        for name, layer in self.items():\n",
    "            new_features = layer(features)\n",
    "            features.append(new_features)\n",
    "        return torch.cat(features, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Transition Layers\n",
    "\n",
    "class TransitionLayer(nn.Sequential):\n",
    "    def __init__(self, input_channels, output_channels):\n",
    "        super(TransitionLayer, self).__init__()\n",
    "        self.add_module('norm', nn.BatchNorm2d(input_channels))\n",
    "        self.add_module('relu',nn.ReLU(inplace=True))\n",
    "        self.add_module('conv',nn.Conv2d(input_channels, output_channels, kernel_size=1, stride=1, bias=False))\n",
    "        self.add_module('pool',nn.AvgPool2d(kernel_size=2, stride=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DenseNet121(nn.Module):\n",
    "\n",
    "    def __init__(self, num_init_channels=64, growth_rate=32,\n",
    "                 bottle_neck_size=4, drop_rate=0.0, num_classes=1000, memory_efficient=False):\n",
    "        super(DenseNet121, self).__init__()\n",
    "\n",
    "        # Initial Convolution\n",
    "        self.features = nn.Sequential(OrderedDict([\n",
    "            ('conv0', nn.Conv2d(3, num_init_channels, kernel_size=7, stride=2, padding=3, bias=False)),\n",
    "            ('norm0', nn.BatchNorm2d(num_init_channels)),\n",
    "            ('relu0', nn.ReLU(inplace=True)),\n",
    "            ('pool0', nn.MaxPool2d(kernel_size=3, stride=2, padding=1)),\n",
    "        ]))\n",
    "\n",
    "        # DenseNet-121 Configuration\n",
    "        block_config = [6, 12, 24, 16]\n",
    "\n",
    "        num_features = num_init_channels\n",
    "\n",
    "        for i, num_layers in enumerate(block_config):\n",
    "            block = DenseBlock(\n",
    "                num_layers=num_layers,\n",
    "                input_channels=num_features,\n",
    "                bottle_neck_size=bottle_neck_size,\n",
    "                growth_rate=growth_rate,\n",
    "                drop_rate=drop_rate,\n",
    "                memory_efficient=memory_efficient\n",
    "            )\n",
    "            self.features.add_module('denseblock%d' % (i + 1), block)\n",
    "            # The number of output channels in the previous dense block\n",
    "            num_features = num_features + num_layers * growth_rate\n",
    "\n",
    "            # A transition layer that halves the number of channels is added between the dense blocks\n",
    "            if i != len(block_config) - 1:\n",
    "                # Add transition layer between denseblocks to downsample\n",
    "                trans = TransitionLayer(input_channels=num_features,\n",
    "                                        output_channels=num_features // 2)\n",
    "                self.features.add_module('Transition%d' % (i + 1), trans)\n",
    "                num_features = num_features // 2\n",
    "\n",
    "\n",
    "        # Final Batch Norm\n",
    "        self.features.add_module('norm5', nn.BatchNorm2d(num_features))\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.classifier = nn.Linear(num_features, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.features(x)\n",
    "        out = F.relu(features, inplace=True)\n",
    "        out = F.adaptive_avg_pool2d(out, (1,1))\n",
    "        out = torch.flatten(out, 1)\n",
    "        out = self.classifier(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "----\n",
    "# Constructing the Model\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y_true):\n",
    "    _, top_class = y_pred.topk(1, dim=1)  # Get the top class predictions directly from logits\n",
    "    equals = top_class == y_true.view(*top_class.shape)  # Compare with true labels\n",
    "    return torch.mean(equals.type(torch.FloatTensor))  # Calculate the mean accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = DenseNet121(drop_rate=0.3, num_classes=4).to(device)\n",
    "num_epochs = 50\n",
    "optimizer=Adam(model.parameters(),lr=0.001, weight_decay=0.0001)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    for inputs, labels in train_dataset:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        train_acc += accuracy(outputs, labels)\n",
    "\n",
    "    train_loss /= len(train_dataset)\n",
    "    train_losses.append(train_loss)\n",
    "    train_acc /= len(train_dataset)\n",
    "    train_accuracies.append(train_acc)\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    test_acc = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_dataset:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            test_acc += accuracy(outputs, labels)\n",
    "\n",
    "    test_loss /= len(test_dataset)\n",
    "    test_losses.append(test_loss)\n",
    "    test_acc /= len(test_dataset)\n",
    "    test_accuracies.append(test_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}, Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(test_losses, label='Testing Loss')\n",
    "plt.title('Training and Testing Losses Per Epoch')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
